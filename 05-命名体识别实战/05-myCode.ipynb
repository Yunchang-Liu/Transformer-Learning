{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2288791/2288791 [00:05<00:00, 420324.44it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('dataset/train.txt', 'r', encoding='utf-8') as f:\n",
    "    to_df = []\n",
    "    count = 1\n",
    "\n",
    "    for line in tqdm(f.read().split('\\n')):\n",
    "        sentence_id = f\"train_{count}\"\n",
    "\n",
    "        if line != '\\n' and len(line.strip())>0:\n",
    "            word_list = line.split()\n",
    "            if len(word_list) == 2:\n",
    "                to_df.append([sentence_id] + word_list)\n",
    "            else: # 如果是空格，split后长度只有1 (tag)\n",
    "                to_df.append([sentence_id, \"[SEP]\", word_list[-1]])\n",
    "\n",
    "        else:\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_1</td>\n",
       "      <td>手</td>\n",
       "      <td>B-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>机</td>\n",
       "      <td>I-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_1</td>\n",
       "      <td>三</td>\n",
       "      <td>B-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_1</td>\n",
       "      <td>脚</td>\n",
       "      <td>I-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_1</td>\n",
       "      <td>架</td>\n",
       "      <td>I-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id words  tags\n",
       "0     train_1     手  B-40\n",
       "1     train_1     机  I-40\n",
       "2     train_1     三   B-4\n",
       "3     train_1     脚   I-4\n",
       "4     train_1     架   I-4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(to_df, columns=['sentence_id', 'words', 'tags'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_1</td>\n",
       "      <td>手</td>\n",
       "      <td>B-40</td>\n",
       "      <td>手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...</td>\n",
       "      <td>B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>机</td>\n",
       "      <td>I-40</td>\n",
       "      <td>手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...</td>\n",
       "      <td>B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_1</td>\n",
       "      <td>三</td>\n",
       "      <td>B-4</td>\n",
       "      <td>手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...</td>\n",
       "      <td>B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_1</td>\n",
       "      <td>脚</td>\n",
       "      <td>I-4</td>\n",
       "      <td>手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...</td>\n",
       "      <td>B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_1</td>\n",
       "      <td>架</td>\n",
       "      <td>I-4</td>\n",
       "      <td>手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...</td>\n",
       "      <td>B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id words  tags                                           sentence  \\\n",
       "0     train_1     手  B-40  手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...   \n",
       "1     train_1     机  I-40  手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...   \n",
       "2     train_1     三   B-4  手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...   \n",
       "3     train_1     脚   I-4  手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...   \n",
       "4     train_1     架   I-4  手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...   \n",
       "\n",
       "                                         word_labels  \n",
       "0  B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...  \n",
       "1  B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...  \n",
       "2  B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...  \n",
       "3  B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...  \n",
       "4  B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentence'] = data[['sentence_id','words','tags']].groupby(['sentence_id'])['words'].transform(lambda x: ' '.join(x))\n",
    "data['word_labels'] = data[['sentence_id','words','tags']].groupby(['sentence_id'])['tags'].transform(lambda x: ','.join(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-40': 0,\n",
       " 'I-40': 1,\n",
       " 'B-4': 2,\n",
       " 'I-4': 3,\n",
       " 'B-14': 4,\n",
       " 'I-14': 5,\n",
       " 'B-5': 6,\n",
       " 'I-5': 7,\n",
       " 'B-7': 8,\n",
       " 'I-7': 9,\n",
       " 'B-11': 10,\n",
       " 'I-11': 11,\n",
       " 'B-13': 12,\n",
       " 'I-13': 13,\n",
       " 'B-8': 14,\n",
       " 'I-8': 15,\n",
       " 'O': 16,\n",
       " 'B-16': 17,\n",
       " 'I-16': 18,\n",
       " 'B-29': 19,\n",
       " 'I-29': 20,\n",
       " 'B-9': 21,\n",
       " 'I-9': 22,\n",
       " 'B-12': 23,\n",
       " 'I-12': 24,\n",
       " 'B-18': 25,\n",
       " 'I-18': 26,\n",
       " 'B-1': 27,\n",
       " 'I-1': 28,\n",
       " 'B-3': 29,\n",
       " 'I-3': 30,\n",
       " 'B-22': 31,\n",
       " 'I-22': 32,\n",
       " 'B-37': 33,\n",
       " 'I-37': 34,\n",
       " 'B-39': 35,\n",
       " 'I-39': 36,\n",
       " 'B-10': 37,\n",
       " 'I-10': 38,\n",
       " 'B-36': 39,\n",
       " 'I-36': 40,\n",
       " 'B-34': 41,\n",
       " 'I-34': 42,\n",
       " 'B-31': 43,\n",
       " 'I-31': 44,\n",
       " 'B-38': 45,\n",
       " 'I-38': 46,\n",
       " 'B-54': 47,\n",
       " 'I-54': 48,\n",
       " 'B-6': 49,\n",
       " 'I-6': 50,\n",
       " 'B-30': 51,\n",
       " 'I-30': 52,\n",
       " 'B-15': 53,\n",
       " 'I-15': 54,\n",
       " 'B-2': 55,\n",
       " 'I-2': 56,\n",
       " 'B-49': 57,\n",
       " 'I-49': 58,\n",
       " 'B-21': 59,\n",
       " 'I-21': 60,\n",
       " 'B-47': 61,\n",
       " 'I-47': 62,\n",
       " 'B-23': 63,\n",
       " 'I-23': 64,\n",
       " 'B-20': 65,\n",
       " 'I-20': 66,\n",
       " 'B-50': 67,\n",
       " 'I-50': 68,\n",
       " 'B-46': 69,\n",
       " 'I-46': 70,\n",
       " 'B-41': 71,\n",
       " 'I-41': 72,\n",
       " 'B-43': 73,\n",
       " 'I-43': 74,\n",
       " 'B-48': 75,\n",
       " 'I-48': 76,\n",
       " 'B-19': 77,\n",
       " 'I-19': 78,\n",
       " 'B-52': 79,\n",
       " 'I-52': 80,\n",
       " 'B-33': 81,\n",
       " 'I-33': 82,\n",
       " 'B-28': 83,\n",
       " 'I-28': 84,\n",
       " 'B-32': 85,\n",
       " 'I-32': 86,\n",
       " 'B-44': 87,\n",
       " 'I-44': 88,\n",
       " 'B-25': 89,\n",
       " 'I-25': 90,\n",
       " 'B-17': 91,\n",
       " 'I-17': 92,\n",
       " 'B-42': 93,\n",
       " 'I-42': 94,\n",
       " 'B-24': 95,\n",
       " 'I-24': 96,\n",
       " 'B-53': 97,\n",
       " 'I-53': 98,\n",
       " 'B-26': 99,\n",
       " 'I-26': 100,\n",
       " 'B-35': 101,\n",
       " 'I-35': 102,\n",
       " 'B-51': 103,\n",
       " 'I-51': 104}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(data.tags.unique())}\n",
    "ids_to_labels = {v: k for v, k in enumerate(data.tags.unique())}\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...</td>\n",
       "      <td>B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>牛 皮 纸 袋 手 提 袋 定 制 l o g o 烘 焙 购 物 服 装 包 装 外 卖 ...</td>\n",
       "      <td>B-4,I-4,I-4,I-4,B-4,I-4,I-4,B-29,I-29,I-29,I-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>彩 色 金 属 镂 空 鱼 尾 夹 长 尾 夹 [SEP] 手 帐 设 计 绘 图 文 具 ...</td>\n",
       "      <td>B-16,I-16,B-12,I-12,B-13,I-13,B-4,I-4,I-4,B-4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B o s e [SEP] S o u n d S p o r t [SEP] F r e ...</td>\n",
       "      <td>B-1,I-1,I-1,I-1,O,B-3,I-3,I-3,I-3,I-3,I-3,I-3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>壁 挂 炉 专 用 水 空 调 散 热 器 带 风 扇 暖 气 片 水 暖 空 调 明 装 ...</td>\n",
       "      <td>B-4,I-4,I-4,O,O,B-4,I-4,I-4,B-4,I-4,I-4,B-22,I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...   \n",
       "1  牛 皮 纸 袋 手 提 袋 定 制 l o g o 烘 焙 购 物 服 装 包 装 外 卖 ...   \n",
       "2  彩 色 金 属 镂 空 鱼 尾 夹 长 尾 夹 [SEP] 手 帐 设 计 绘 图 文 具 ...   \n",
       "3  B o s e [SEP] S o u n d S p o r t [SEP] F r e ...   \n",
       "4  壁 挂 炉 专 用 水 空 调 散 热 器 带 风 扇 暖 气 片 水 暖 空 调 明 装 ...   \n",
       "\n",
       "                                         word_labels  \n",
       "0  B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...  \n",
       "1  B-4,I-4,I-4,I-4,B-4,I-4,I-4,B-29,I-29,I-29,I-2...  \n",
       "2  B-16,I-16,B-12,I-12,B-13,I-13,B-4,I-4,I-4,B-4,...  \n",
       "3  B-1,I-1,I-1,I-1,O,B-3,I-3,I-3,I-3,I-3,I-3,I-3,...  \n",
       "4  B-4,I-4,I-4,O,O,B-4,I-4,I-4,B-4,I-4,I-4,B-22,I...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
    "# 也可以根据sentence_id去重\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39995.000000\n",
       "mean        56.220828\n",
       "std         13.473300\n",
       "min          7.000000\n",
       "25%         46.000000\n",
       "50%         56.000000\n",
       "75%         65.000000\n",
       "max        101.000000\n",
       "Name: sentence, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentence'].apply(lambda x:len(x.split(' '))).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 105 \n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-05\n",
    "MAX_GRAD_NORM = 5\n",
    "MODEL_NAME='bert-base-chinese'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME) # encode_plus()# 整体"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \n",
    "    tokenized_sentences = []\n",
    "    labels = []\n",
    "    sentence = sentence.strip() \n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(',')):\n",
    "        tokenized_word = tokenizer.tokenize(word)  # 逐字分词\n",
    "        len_after_tok = len(tokenized_word)\n",
    "\n",
    "        tokenized_sentences.extend(tokenized_word)  # 将单个字分词结果追加到句子分词列表\n",
    "        labels.extend([label] * len_after_tok)  # 一个词tokenizer后可能会变成多个，将其每一个部分的label都标记为相同\n",
    "    \n",
    "    return tokenized_sentences, labels,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence       手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...\n",
       "word_labels    B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize_and_preserve_labels(data.iloc[0]['sentence'],data.iloc[0]['word_labels'],tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 步骤 1: 对每个句子分词\n",
    "        sentence = self.data['sentence'][index]\n",
    "        text_labels = self.data['word_labels'][index]\n",
    "        words_list, labels = tokenize_and_preserve_labels(sentence, text_labels, self.tokenizer)\n",
    "\n",
    "        # 步骤 2: 添加特殊token并添加对应的标签\n",
    "        words_list = [\"[CLS]\"] + words_list + [\"[SEP]\"]\n",
    "        labels = [\"O\"] + labels + [\"O\"]\n",
    "\n",
    "        # 步骤 3: 截断/填充\n",
    "        if len(words_list) > self.max_len:\n",
    "            words_list = words_list[:self.max_len]\n",
    "            labels = labels[:self.max_len]\n",
    "        elif len(words_list) < self.max_len:\n",
    "            # words_list = words_list + ['[PAD]'for _ in range(self.max_len - len(words_list))]\n",
    "            # labels = labels + [\"O\" for _ in range(self.max_len - len(labels))]\n",
    "\n",
    "            # 用extend不需要赋值！！！\n",
    "            words_list.extend((self.max_len-len(words_list)) * [\"[PAD]\"])\n",
    "            labels.extend((self.max_len-len(labels)) * \"O\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # 步骤 4: 构建attention mask\n",
    "        attention_masks = [1 if word != \"[PAD]\" else 0 for word in words_list]\n",
    "\n",
    "        # 步骤 5: 将分词结果转为词表的id表示\n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(words_list)\n",
    "        label_ids = [labels_to_ids[label] for label in labels]\n",
    "\n",
    "        return {\n",
    "            \"ids\" : torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"masks\" : torch.tensor(attention_masks, dtype=torch.long),\n",
    "            \"targets\" : torch.tensor(label_ids, dtype=torch.long)\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (39995, 2)\n",
      "TRAIN Dataset: (31996, 2)\n",
      "TEST Dataset: (7999, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(data,test_size=0.2,random_state=42)\n",
    "\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "test_dataset = test_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = MyDataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = MyDataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([ 101,  881, 5543, 8020,  100,  143,  156,  157,  156, 8021,  100,  100,\n",
       "          100,  123,  130,  121,  121,  116, 7946, 4635, 4080, 1045, 2802, 1313,\n",
       "         3322, 2207, 1798, 4080, 1045, 2802, 1313, 3322,  100,  125, 2802, 1313,\n",
       "         3322, 1555, 1218, 2157, 4500, 1215, 1062,  102, 2135, 3175, 3403, 6981,\n",
       "          116,  122, 3118,  881, 5543, 1333, 6163, 4797, 7961,  102,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'masks': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'targets': tensor([16, 27, 28, 16, 27, 28, 28, 28, 28, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         17, 18,  2,  3,  3,  3,  3, 12, 13,  2,  3,  3,  3,  3, 25, 26,  2,  3,\n",
       "          3,  6,  7,  8,  9,  6,  7, 16, 16, 16, 16, 16, 16, 25, 26, 27, 28,  4,\n",
       "          5, 31, 32, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 创建dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True,  num_workers=0)\n",
    "test_dataloader = DataLoader(testing_set, batch_size=VALID_BATCH_SIZE, shuffle=True,  num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=105, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出有两个：一个为loss和一个为logits\n",
    "model = BertForTokenClassification.from_pretrained(MODEL_NAME, num_labels=len(labels_to_ids))\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 模型训练"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT模型的输入是都是(batch_size, sequence_length)，即二维张量     \n",
    "如果准备的输入是一维张量，需要.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型输出有两个：一个为loss和一个为logits      \n",
    "logits维度为 (batch_size, sequence_length, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train():\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    num_tr_steps = 0\n",
    "    # 将model设置为train模式\n",
    "    model.train()\n",
    "\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        input_ids = data[\"ids\"].to(device, dtype=torch.long)\n",
    "        attention_masks = data[\"masks\"].to(device, dtype=torch.long)\n",
    "        labels = data[\"targets\"].to(device, dtype=torch.long)\n",
    "        # 模型输出有两个：一个为loss和一个为logits \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_masks, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        num_tr_steps += 1\n",
    "\n",
    "        if idx % 500==0:\n",
    "            loss_step = tr_loss/num_tr_steps\n",
    "            print(f\"Training loss per 500 training steps: {loss_step}\")\n",
    "        \n",
    "        # 计算准确率\n",
    "        flattened_labels = labels.view(-1)  # 本来是二维: batch个labels组成的列表,展平成一维(batch_size * seq_len)\n",
    "        active_logits = logits.view(-1, model.num_labels) # 模型输出shape (batch_size * seq_len, num_labels)\n",
    "        flattened_logits = torch.argmax(active_logits, axis=1)\n",
    "\n",
    "        # MASK所有的[PAD]\n",
    "        activate_accuracy = attention_masks.view(-1) == 1\n",
    "        targets = torch.masked_select(flattened_labels, activate_accuracy)\n",
    "        predictions = torch.masked_select(flattened_logits, activate_accuracy)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "        # 梯度剪切\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # loss反向求导\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss/num_tr_steps \n",
    "    tr_accuracy = tr_accuracy/num_tr_steps\n",
    "\n",
    "\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
    "\n",
    "# # 训练函数\n",
    "# def train():\n",
    "#     tr_loss, tr_accuracy = 0, 0\n",
    "#     nb_tr_examples, nb_tr_steps = 0, 0\n",
    "#     tr_preds, tr_labels = [], []\n",
    "#     # 将model设置为train模式\n",
    "#     model.train()\n",
    "    \n",
    "#     for idx, batch in enumerate(train_dataloader):\n",
    "        \n",
    "#         ids = batch['ids'].to(device, dtype = torch.long) #(4,91)\n",
    "#         mask = batch['masks'].to(device, dtype = torch.long) #(4,91)\n",
    "#         targets = batch['targets'].to(device, dtype = torch.long)#(4,91)\n",
    "        \n",
    "        \n",
    "#         outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "#         loss, tr_logits = outputs[0],outputs[1]\n",
    "#         # print(outputs.keys())\n",
    "#         # print(loss)\n",
    "#         tr_loss += loss.item()\n",
    "\n",
    "#         nb_tr_steps += 1\n",
    "#         nb_tr_examples += targets.size(0)\n",
    "        \n",
    "#         if idx % 500==0:\n",
    "#             loss_step = tr_loss/nb_tr_steps\n",
    "#             print(f\"Training loss per 500 training steps: {loss_step}\")\n",
    "            \n",
    "#         # 计算准确率\n",
    "#         flattened_targets = targets.view(-1) # 真实标签 大小 (batch_size * seq_len,)\n",
    "#         active_logits = tr_logits.view(-1, model.num_labels) # 模型输出shape (batch_size * seq_len, num_labels)\n",
    "#         flattened_predictions = torch.argmax(active_logits, axis=1) # 取出每个token对应概率最大的标签索引 shape (batch_size * seq_len,)\n",
    "#         # MASK：PAD\n",
    "#         active_accuracy = mask.view(-1) == 1 # shape (batch_size * seq_len,)\n",
    "#         targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "#         predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "#         tr_preds.extend(predictions)\n",
    "#         tr_labels.extend(targets)\n",
    "        \n",
    "#         tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "#         tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "#         # 梯度剪切\n",
    "#         torch.nn.utils.clip_grad_norm_(\n",
    "#             parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "#         )\n",
    "        \n",
    "#         # loss反向求导\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     epoch_loss = tr_loss / nb_tr_steps\n",
    "#     tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "#     print(f\"Training loss epoch: {epoch_loss}\")\n",
    "#     print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 500 training steps: 4.975777626037598\n",
      "Training loss per 500 training steps: 0.7366198420286655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [04:22<39:21, 262.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.578648552685976\n",
      "Training accuracy epoch: 0.7367803948284127\n",
      "Training epoch: 2\n",
      "Training loss per 500 training steps: 0.38794592022895813\n",
      "Training loss per 500 training steps: 0.36900885650021825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [08:44<34:59, 262.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.3630326453745365\n",
      "Training accuracy epoch: 0.8079709533593953\n",
      "Training epoch: 3\n",
      "Training loss per 500 training steps: 0.33696943521499634\n",
      "Training loss per 500 training steps: 0.3307598065175934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [13:06<30:34, 262.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.3265049105137587\n",
      "Training accuracy epoch: 0.8221002438426439\n",
      "Training epoch: 4\n",
      "Training loss per 500 training steps: 0.2537868320941925\n",
      "Training loss per 500 training steps: 0.3028521772451743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [17:28<26:11, 261.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.30267235822975636\n",
      "Training accuracy epoch: 0.8320443464149426\n",
      "Training epoch: 5\n",
      "Training loss per 500 training steps: 0.25788819789886475\n",
      "Training loss per 500 training steps: 0.28069474680457046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [21:59<22:07, 265.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.28155801248550416\n",
      "Training accuracy epoch: 0.8418065281234389\n",
      "Training epoch: 6\n",
      "Training loss per 500 training steps: 0.29722538590431213\n",
      "Training loss per 500 training steps: 0.26301350270559687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [26:31<17:50, 267.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.2634354070276022\n",
      "Training accuracy epoch: 0.8501485241984149\n",
      "Training epoch: 7\n",
      "Training loss per 500 training steps: 0.18836061656475067\n",
      "Training loss per 500 training steps: 0.24313516703670374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [31:04<13:27, 269.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.24625737877190113\n",
      "Training accuracy epoch: 0.8592509421093886\n",
      "Training epoch: 8\n",
      "Training loss per 500 training steps: 0.21763837337493896\n",
      "Training loss per 500 training steps: 0.2285180841079967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [35:36<09:00, 270.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.23069896318018437\n",
      "Training accuracy epoch: 0.8663544738335778\n",
      "Training epoch: 9\n",
      "Training loss per 500 training steps: 0.1858900934457779\n",
      "Training loss per 500 training steps: 0.2112922418617203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [40:08<04:30, 270.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.21540155093371868\n",
      "Training accuracy epoch: 0.874740610315942\n",
      "Training epoch: 10\n",
      "Training loss per 500 training steps: 0.1846655309200287\n",
      "Training loss per 500 training steps: 0.19838245621995773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [44:31<00:00, 267.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.20167457877844572\n",
      "Training accuracy epoch: 0.8818991130050614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['masks'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            # loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs[0],outputs[1]\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # 计算准确率\n",
    "            flattened_targets = targets.view(-1) # 大小 (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # 大小 (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # 大小 (batch_size * seq_len,)\n",
    "            active_accuracy = mask.view(-1) == 1 # 大小 (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #print(eval_labels)\n",
    "    #print(eval_preds)\n",
    "\n",
    "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.43385112285614014\n",
      "Validation loss per 100 evaluation steps: 0.3679109271800164\n",
      "Validation loss per 100 evaluation steps: 0.3735577353642355\n",
      "Validation Loss: 0.3728489454388618\n",
      "Validation Accuracy: 0.8158323835892893\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
